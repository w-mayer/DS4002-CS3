{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "857962f3",
   "metadata": {},
   "source": [
    "In this file, we'll accomplish the following:\n",
    "\n",
    "1. Cut out a small piece of a large dataset (so that we can run this exercise meaningfully without high performance computing resources)\n",
    "2. Employ natural language processing (NLP) techniques to analyze the emotional sentiment of email text\n",
    "3. Encode email text into TF-IDF vectorizations\n",
    "\n",
    "By the end of the file, you'll turn a dataset of email text into a ready-to-model dataset with engineered features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0de8e25",
   "metadata": {},
   "source": [
    "DISCLAIMER: Because this project contains real phishing email text, there is inappropriate language in the email text. Please do not inspect this variable if you are not comfortable with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4b187d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121374e1",
   "metadata": {},
   "source": [
    "First, we'll load in our raw dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0c62cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DATA/raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc7dc8b",
   "metadata": {},
   "source": [
    "These cells pull out sample_size (default 2,000) rows from the full dataset to cut off a small sample that should run on students laptops. Note that we've used the 'stratify' argument which ensures our sample has an equal balance of phishing and safe emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45cd90a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8a41dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a stratified sample of 5000 observations\n",
    "_, df = train_test_split(\n",
    "    df,\n",
    "    test_size=sample_size,       # Number of samples you want\n",
    "    stratify=df['email_type'],  # Stratify on the phishing/safe label\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51bafda",
   "metadata": {},
   "source": [
    "#### Sentiment Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b816f2",
   "metadata": {},
   "source": [
    "Sentiment analysis is the process of identifying emotional tone behind a body of text.\n",
    "\n",
    "We are using the VADER (Valence Aware Dictionary and sEntiment Reasoner) tool, which is\n",
    "designed to detect sentiment in short pieces of text (like email bodies).\n",
    "\n",
    "For each email, VADER gives us four scores:\n",
    "- 'neg': proportion of the text that is negative\n",
    "- 'neu': proportion that is neutral\n",
    "- 'pos': proportion that is positive\n",
    "- 'compound': an overall sentiment score, ranging from -1 (extremely negative) to +1 (extremely positive)\n",
    "\n",
    "These sentiment features can help us detect patterns: for example, phishing emails might use\n",
    "stronger negative or urgent emotional language compared to safe emails.\n",
    "\n",
    "In this step, we apply VADER to each email and expand the results into new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df5e8f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to calculate sentiment scores\n",
    "def get_sentiment(text):\n",
    "    return sia.polarity_scores(text)\n",
    "\n",
    "sentiment_df = df['email_text'].apply(get_sentiment).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf0364",
   "metadata": {},
   "source": [
    "#### TF-IDF Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40037c27",
   "metadata": {},
   "source": [
    "TF-IDF stands for \"Term Frequency - Inverse Document Frequency.\"\n",
    "\n",
    "It transforms raw text into numerical features by measuring:\n",
    "- How often a word appears in a specific document (term frequency)\n",
    "- How unique that word is across all documents (inverse document frequency)\n",
    "\n",
    "Words that appear often in one email but rarely across the full dataset are considered\n",
    "more important, and get higher TF-IDF scores.\n",
    "\n",
    "In this project, we use TF-IDF to capture meaningful words or short phrases (unigrams and bigrams)\n",
    "from each email. These will act as input features for our machine learning model.\n",
    "\n",
    "We also:\n",
    "- Remove common stopwords like \"the,\" \"and,\" \"is,\" etc. that don't add meaning\n",
    "- Limit the vocabulary to the top 5000 most important words/phrases to reduce memory use\n",
    "\n",
    "The result is a matrix where each row is an email and each column represents the importance\n",
    "of a specific word or phrase in that email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2610924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english', max_features=5000)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['email_text'])\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(), \n",
    "    columns=vectorizer.get_feature_names_out(), \n",
    "    index=df.index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f813a04",
   "metadata": {},
   "source": [
    "Our final df for EDA and modeling has labelled (phishing or safe) email text encoded in TF-IDF vectors along with sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b3c1d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat(\n",
    "    [\n",
    "        sentiment_df[['neg', 'neu', 'pos', 'compound']],  # Sentiment columns\n",
    "        tfidf_df,                                         # TF-IDF features\n",
    "        df[['email_type']]                                # Target variable\n",
    "    ],\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a86e7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_parquet('../DATA/final.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
